services:
  webapp:
    build:
      context: .
      dockerfile: apps/webapp/Dockerfile
      args:
        ENV_FILE: ${ENV_FILE:-.env.localhost}
    ports:
      - "3000:3000"
    env_file:
      - ${ENV_FILE:-.env.localhost}
  db-init:
    build:
      context: .
      dockerfile: apps/webapp/Dockerfile
    command: >
      sh -c "npm run db:migrate:deploy && npm run db:seed"
    environment:
      - POSTGRES_URL_NON_POOLING=${POSTGRES_URL_NON_POOLING}
      - POSTGRES_PRISMA_URL=${POSTGRES_PRISMA_URL}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    depends_on:
      postgres:
        condition: service_healthy
  postgres:
    image: pgvector/pgvector:pg15
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    environment:
      - POSTGRES_URL_NON_POOLING=${POSTGRES_URL_NON_POOLING}
      - POSTGRES_PRISMA_URL=${POSTGRES_PRISMA_URL}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./apps/webapp/prisma/pgvector-init:/docker-entrypoint-initdb.d
  inference:
    platform: linux/amd64
    build:
      context: .
      dockerfile: apps/inference/Dockerfile
      args:
        BUILD_TYPE: nocuda # ${BUILD_TYPE:-nocuda} # Use nocuda by default, override with BUILD_TYPE=cuda
        CUDA_VERSION: "12.1.0"
        UBUNTU_VERSION: "22.04"
    ports:
      - "5002:5002"
    environment:
      - MODEL_ID=gpt2-small
      - OVERRIDE_MODEL_ID=gpt2-small
      - MODEL_DTYPE=float32
      - SAE_DTYPE=float32
      - SAE_SETS=["res-jb"]
      - MAX_LOADED_SAES=200
      - HF_TOKEN=${HF_TOKEN}
      - SECRET=${INFERENCE_SERVER_SECRET}
      - SENTRY_DSN=${SENTRY_DSN_INFERENCE}
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    #     limits:
    #       memory: 8G

  autointerp:
    platform: linux/amd64
    build:
      context: .
      dockerfile: apps/autointerp/Dockerfile
      args:
        BUILD_TYPE: nocuda # ${BUILD_TYPE:-nocuda}
        CUDA_VERSION: "12.1.0"
        UBUNTU_VERSION: "22.04"
    ports:
      - "5003:5003"
    environment:
      - SENTRY_DSN=${SENTRY_DSN_AUTOINTERP}
    command: >
      python -m uvicorn server:app
      --host 0.0.0.0
      --port 5003
      --workers 1
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    #     limits:
    #       memory: 8G

volumes:
  postgres_data:

networks:
  default:
    name: memicos-network
