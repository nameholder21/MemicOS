{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Activations All"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success: {'error': 'Invalid request data'}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://localhost:5002/activations-all\"\n",
        "\n",
        "payload = {\n",
        "    \"text\": \"zzz\",\n",
        "    \"model\": \"gpt2-small\",\n",
        "    \"source_set\": \"gpt2-small-res-jb\",\n",
        "    \"selected_layers\": [\"blocks.6.hook_resid_pre\"],\n",
        "    \"secret\": \"secret\",\n",
        "    \"sort_indexes\": []\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload)\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    print(\"Success:\", response.json())\n",
        "else:\n",
        "    print(\"Failed:\", response.status_code, response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(response, \"response_v1.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success: {'activations': [{'index': 67074, 'layer': '23-res-cat', 'maxValue': 358.0, 'maxValueIndex': 1, 'sumValues': 0.0, 'values': [222.0, 358.0, 0.0]}, {'index': 56918, 'layer': '23-res-cat', 'maxValue': 42.75, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 22.625, 42.75]}, {'index': 62094, 'layer': '23-res-cat', 'maxValue': 42.0, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 42.0]}, {'index': 94658, 'layer': '23-res-cat', 'maxValue': 33.0, 'maxValueIndex': 1, 'sumValues': 0.0, 'values': [0.0, 33.0, 0.0]}, {'index': 68063, 'layer': '23-res-cat', 'maxValue': 30.125, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 30.125]}, {'index': 1209, 'layer': '23-res-cat', 'maxValue': 28.5, 'maxValueIndex': 1, 'sumValues': 0.0, 'values': [0.0, 28.5, 6.125]}, {'index': 17205, 'layer': '23-res-cat', 'maxValue': 25.25, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 11.25, 25.25]}, {'index': 55897, 'layer': '23-res-cat', 'maxValue': 25.25, 'maxValueIndex': 1, 'sumValues': 0.0, 'values': [0.0, 25.25, 0.0]}, {'index': 46997, 'layer': '23-res-cat', 'maxValue': 24.0, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 24.0]}, {'index': 11075, 'layer': '23-res-cat', 'maxValue': 22.25, 'maxValueIndex': 1, 'sumValues': 0.0, 'values': [0.0, 22.25, 0.0]}, {'index': 58500, 'layer': '23-res-cat', 'maxValue': 21.875, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 21.875]}, {'index': 120440, 'layer': '23-res-cat', 'maxValue': 21.75, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 21.75]}, {'index': 90671, 'layer': '23-res-cat', 'maxValue': 20.25, 'maxValueIndex': 1, 'sumValues': 0.0, 'values': [0.0, 20.25, 0.0]}, {'index': 106125, 'layer': '23-res-cat', 'maxValue': 19.75, 'maxValueIndex': 1, 'sumValues': 0.0, 'values': [0.0, 19.75, 0.0]}, {'index': 84790, 'layer': '23-res-cat', 'maxValue': 19.625, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 19.625]}, {'index': 104062, 'layer': '23-res-cat', 'maxValue': 18.5, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 18.5]}, {'index': 96866, 'layer': '23-res-cat', 'maxValue': 17.875, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 17.875]}, {'index': 54592, 'layer': '23-res-cat', 'maxValue': 17.25, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 17.25]}, {'index': 44154, 'layer': '23-res-cat', 'maxValue': 17.0, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 17.0]}, {'index': 108353, 'layer': '23-res-cat', 'maxValue': 15.75, 'maxValueIndex': 1, 'sumValues': 0.0, 'values': [0.0, 15.75, 0.0]}, {'index': 55719, 'layer': '23-res-cat', 'maxValue': 15.25, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 11.5, 15.25]}, {'index': 3444, 'layer': '23-res-cat', 'maxValue': 14.375, 'maxValueIndex': 1, 'sumValues': 0.0, 'values': [0.0, 14.375, 6.75]}, {'index': 121274, 'layer': '23-res-cat', 'maxValue': 14.125, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 14.125]}, {'index': 68770, 'layer': '23-res-cat', 'maxValue': 13.25, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 13.25]}, {'index': 41410, 'layer': '23-res-cat', 'maxValue': 11.125, 'maxValueIndex': 2, 'sumValues': 0.0, 'values': [0.0, 0.0, 11.125]}], 'counts': [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [5032.0, 23.0, 56.0]], 'tokens': ['<bos>', 'zzzz', 'zz']}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://localhost:5002/activations-all\"\n",
        "\n",
        "payload = {\n",
        "    \"text\": \"zzzzzz\",\n",
        "    \"model\": \"gemma-2-9b\",\n",
        "    \"source_set\": \"res-cat\",\n",
        "    \"selected_layers\": [\"23-res-cat\"],\n",
        "    \"secret\": \"secret\",\n",
        "    \"sort_indexes\": []\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload)\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    print(\"Success:\", response.json())\n",
        "else:\n",
        "    print(\"Failed:\", response.status_code, response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(response.json()['activations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['activations', 'counts', 'tokens'])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.json().keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(response, \"response_v2.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rv1 = torch.load(\"response_v1.pt\")\n",
        "rv2 = torch.load(\"response_v2.pt\")\n",
        "\n",
        "rv1 == rv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for activation in rv1.json()['activations'].keys():\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(rv1.json()['activations'])):\n",
        "    assert rv1.json()['activations'][i]==rv2.json()['activations'][i]\n",
        "for i in range(len(rv1.json()['counts'])):\n",
        "    assert rv1.json()['counts'][i]==rv2.json()['counts'][i]\n",
        "for i in range(len(rv1.json()['tokens'])):\n",
        "    assert rv1.json()['tokens'][i]==rv2.json()['tokens'][i]\n",
        "    \n",
        "assert len(rv1.json()['activations']) == len(rv2.json()['activations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rv1.json() == rv2.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success: {'activations': {'maxValue': 0.0, 'maxValueIndex': 0, 'values': [0.0, 0.0]}, 'tokens': ['<bos>', 'zzz']}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://localhost:5002/activations-test\"\n",
        "\n",
        "payload = {\n",
        "    \"text\": \"zzz\",\n",
        "    \"model\": \"gemma-2-9b\",\n",
        "    \"layer\": \"23-res-cat\",\n",
        "    \"layer_num\": 23,\n",
        "    \"index\": \"5\",\n",
        "    \"secret\": \"secret\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload)\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    print(\"Success:\", response.json())\n",
        "else:\n",
        "    print(\"Failed:\", response.status_code, response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from saes.saelens import SaeLensSAE\n",
        "from sae_lens import HookedSAETransformer\n",
        "\n",
        "os.environ[\"GEMMA_2_SAE_WEIGHTS_ROOT\"] = \"/root/memicos-inference/memicos_inference/saes/weights/\"\n",
        "\n",
        "sae, hook_name = SaeLensSAE.load(\n",
        "    release=\"gemma-2-saes\",\n",
        "    sae_id=\"23/post_mlp_residual/131072/0_0005\",\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e51e7624ecb497584842af09dd61b6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model gemma-2-9b into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "model = HookedSAETransformer.from_pretrained_no_processing(\"gemma-2-9b\", device=\"cuda\", dtype=\"bfloat16\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch \n",
        "\n",
        "text = \"zzz\"\n",
        "device = \"cuda\"\n",
        "\n",
        "#model = HookedSAETransformer.from_pretrained_no_processing(\"gemma-2-9b\", device=\"cuda\", dtype=\"bfloat16\")\n",
        "\n",
        "sae, hook_name = SaeLensSAE.load(\n",
        "    release=\"gemma-2-saes\",\n",
        "    sae_id=\"23/post_mlp_residual/131072/0_0005\",\n",
        "    device=\"cuda\",\n",
        ")\n",
        "\n",
        "tokens = model.to_tokens(\n",
        "    text, prepend_bos=model.cfg.tokenizer_prepends_bos, truncate=False\n",
        ")[0]\n",
        "str_tokens = model.to_str_tokens(\n",
        "    text, prepend_bos=model.cfg.tokenizer_prepends_bos\n",
        ")\n",
        "_, cache = model.run_with_cache(tokens, stop_at_layer=24)\n",
        "\n",
        "activation_data = cache[hook_name].to(device)\n",
        "\n",
        "feature_activation_data = sae.encode(\n",
        "    activation_data\n",
        ")\n",
        "act_data = torch.transpose(feature_activation_data.squeeze(0), 0, 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 131072])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_activation_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 3584])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cache['blocks.23.hook_resid_post'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Completions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success: {'DEFAULT': 'Hello, world! Yours truly,\\n\\nSebastian\\n\\nVitality\\n\\nFascinating\\n\\nInteresting\\n\\nInteresting\\n\\nInteresting\\n\\nInteresting\\n\\nInteresting\\n\\nInteresting\\n\\nInteresting\\n\\n', 'STEERED': \"Hello, world!\\n\\nWe are a team of believers. Who are our fellow Saints, who are our friends, who are our friends? And who are our friends who are living God's plan? Who will? Who will die for His Command? Who will be\"}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://localhost:5002/completion\"\n",
        "\n",
        "payload = {\n",
        "    'prompt': 'Hello, world!', \n",
        "    'secret': 'change_me_secret', \n",
        "    'features': [{'layer': 'blocks.9.hook_resid_pre', 'index': 21871, 'strength': 30.0}], \n",
        "    'model': 'gpt2-small', \n",
        "    'instruct': False, \n",
        "    'types': ['DEFAULT', 'STEERED'], \n",
        "    'n_completion_tokens': 50, \n",
        "    'temperature': 0.7, \n",
        "    'strength_multiplier': 1.5, \n",
        "    'freq_penalty': 0.0, \n",
        "    'seed': 74\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload)\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    print(\"Success:\", response.json())\n",
        "else:\n",
        "    print(\"Failed:\", response.status_code, response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success: {'DEFAULT': \"<bos><start_of_turn>user\\nHello, Gemma! What can you teach me to do?<end_of_turn>\\n<start_of_turn>model\\nHello! I'd love to help you learn and grow. What would you like to learn more about today?\\n\\nI can help with a variety of topics, including:\\n\\n* **Language learning:** I can provide you with language lessons in English\", 'STEERED': \"<bos><start_of_turn>user\\nHello, Gemma! What can you teach me to do?<end_of_turn>\\n<start_of_turn>model\\npowering on! I'd love to help you learn some new things. What would you like to learn?\\n\\nHere are some examples of the things I can help you with:\\n\\n* **Basic skills:** learning to use a computer, reading\"}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://localhost:5002/completion\"\n",
        "\n",
        "payload = {\n",
        "    'prompt': 'Hello, Gemma! What can you teach me to do?', \n",
        "    'secret': 'change_me_secret', \n",
        "    'features': [{'layer': 'blocks.12.hook_resid_post', 'index': 13132, 'strength': 30.0}], \n",
        "    'model': 'gemma-2b-it', \n",
        "    'instruct': True, \n",
        "    'types': ['DEFAULT', 'STEERED'], \n",
        "    'n_completion_tokens': 50, \n",
        "    'temperature': 0.7, \n",
        "    'strength_multiplier': 2.5, \n",
        "    'freq_penalty': 0.0, \n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload)\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    print(\"Success:\", response.json())\n",
        "else:\n",
        "    print(\"Failed:\", response.status_code, response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
